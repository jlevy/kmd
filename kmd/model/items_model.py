"""
The data model for Items and their file formats.
"""

from copy import deepcopy
from dataclasses import asdict, field, is_dataclass
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Type, TypeVar

from frontmatter_format import from_yaml_string, new_yaml
from pydantic.dataclasses import dataclass
from slugify import slugify

from kmd.config.logger import get_logger
from kmd.errors import FileFormatError
from kmd.model.args_model import fmt_loc, Locator
from kmd.model.canon_concept import canonicalize_concept
from kmd.model.file_formats_model import FileExt, Format
from kmd.model.media_model import MediaMetadata
from kmd.model.operations_model import OperationSummary, Source
from kmd.model.paths_model import fmt_store_path, StorePath
from kmd.text_formatting.markdown_util import markdown_to_html
from kmd.util.format_utils import (
    abbreviate_on_words,
    abbreviate_phrase_in_middle,
    clean_up_title,
    html_to_plaintext,
    plaintext_to_html,
)
from kmd.util.log_calls import log_calls
from kmd.util.obj_utils import abbreviate_obj
from kmd.util.strif import format_iso_timestamp
from kmd.util.url import Url

log = get_logger(__name__)

T = TypeVar("T")


class ItemType(Enum):
    """
    Kinds of items. The `ItemType` represents the way it is used by the user,
    and not necessarily the format of the data. For example, an HTML file could
    be a resource (something imported from the web) or a doc (something written
    or being processed by the user) or an export (something generated by for
    a specific use).
    """

    doc = "doc"
    concept = "concept"
    resource = "resource"
    asset = "asset"
    config = "config"
    export = "export"
    chat = "chat"
    extension = "extension"
    script = "script"

    @property
    def expects_body(self) -> bool:
        """
        Resources don't have a body. On concepts it's optional.
        """
        return self.value not in [ItemType.resource.value, ItemType.concept.value]


class State(Enum):
    """
    Review state of an item. Draft is default. Transient is used for items that may be
    safely auto-archived.
    """

    draft = "draft"
    reviewed = "reviewed"
    transient = "transient"


class IdType(Enum):
    """
    Types of identity checks.
    """

    url = "url"
    concept = "concept"
    source = "source"


@dataclass(frozen=True)
class ItemId:
    """
    Represents the identity of an item. The id is used as a shortcut to determine
    if an object already exists.

    The identity of an entity like a URL or a concept is just itself.

    The identity of some items is their source, i.e. the process by which
    they were created, e.g. a transcription of a URL.
    We can decide if an item already exists if we have an output of the same
    action on the exact same inputs, and the action is cacheable (i.e. we consider
    it deterministic).

    If the item is something like a chat with the user, it has no item id because
    every chat is unique (a chat action would be non-cacheable).
    """

    type: ItemType
    id_type: IdType
    value: str

    def id_str(self):
        return f"id:{self.id_type.value}:{self.value.replace(' ', '_')}"

    def __str__(self):
        return self.id_str()

    @classmethod
    def for_item(cls, item: "Item") -> Optional["ItemId"]:
        from kmd.model.canon_url import canonicalize_url

        item_id = None
        if item.type == ItemType.resource and item.format == Format.url and item.url:
            item_id = ItemId(item.type, IdType.url, canonicalize_url(item.url))
        elif item.type == ItemType.concept and item.title:
            item_id = ItemId(item.type, IdType.concept, canonicalize_concept(item.title))
        elif item.source and item.source.cacheable:
            # We know the source of this and if the action was cacheable, we can create
            # an identity based on the source.
            item_id = ItemId(item.type, IdType.source, item.source.as_str())
        else:
            # If we got here, the item has no identity.
            item_id = None

        return item_id


@dataclass
class ItemRelations:
    """
    Relations of a given item to other items.
    """

    derived_from: Optional[List[Locator]] = None
    diff_of: Optional[List[Locator]] = None

    # TODO: Other relations.
    # citations: Optional[List[Locator]] = None
    # named_entities: Optional[List[Locator]] = None
    # related_concepts: Optional[List[Locator]] = None


UNTITLED = "Untitled"

SLUG_MAX_LEN = 64


@dataclass
class Item:
    """
    An Item is any piece of information we may wish to save or perform operations on, such as
    a text document, PDF or other resource, URL, etc.
    """

    type: ItemType
    state: State = State.draft
    title: Optional[str] = None
    url: Optional[Url] = None
    description: Optional[str] = None
    format: Optional[Format] = None
    file_ext: Optional[FileExt] = None

    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    modified_at: Optional[datetime] = None

    # TODO: Consider adding aliases and tags. See also Obsidian frontmatter format:
    # https://help.obsidian.md/Editing+and+formatting/Properties#Default%20properties

    # Content of the item.
    # Text items are in body. Large or binary items may be stored externally.
    body: Optional[str] = None
    external_path: Optional[str] = None

    # Path to the item in the store, if it has been saved.
    store_path: Optional[str] = None

    # Optionally, relations to other items, including any time this item is derived from.
    relations: ItemRelations = field(default_factory=ItemRelations)

    # The operation that created this item.
    source: Optional[Source] = None

    # Optionally, a history of operations.
    history: Optional[List[OperationSummary]] = None

    # Optionally, a URL to a thumbnail image for this item.
    thumbnail_url: Optional[Url] = None

    # Optional additional metadata.
    extra: Optional[dict] = None

    # These fields we don't want in YAML frontmatter.
    # We don't include store_path as it's redundant with the filename.
    NON_METADATA_FIELDS = ["file_ext", "body", "external_path", "store_path"]

    def __post_init__(self):
        assert isinstance(self.type, ItemType)
        assert self.format is None or isinstance(self.format, Format)
        assert self.file_ext is None or isinstance(self.file_ext, FileExt)

        if not isinstance(self.relations, ItemRelations):
            self.relations = ItemRelations(**self.relations)

    @classmethod
    def from_dict(cls, item_dict: Dict[str, Any], **kwargs) -> "Item":
        """
        Deserialize fields from a dict that may include string and dict values.
        """
        item_dict = {**item_dict, **kwargs}

        info_prefix = (
            f"{fmt_store_path(item_dict['store_path'])}: " if "store_path" in item_dict else ""
        )

        # Metadata formats might change over time so it's important to gracefully handle issues.
        def set_field(key: str, default: Any, cls_: Type[T]) -> T:
            try:
                if key in item_dict:
                    return cls_(item_dict[key])  # type: ignore
                else:
                    return default
            except (KeyError, ValueError) as e:
                log.warning(
                    "Error reading %sfield `%s` so using default %r: %s",
                    info_prefix,
                    key,
                    default,
                    e,
                )
                return default

        # These are the enum and dataclass fields.
        type_ = set_field("type", ItemType.doc, ItemType)
        state = set_field("state", State.draft, State)
        format = set_field("format", None, Format)
        file_ext = set_field("file_ext", None, FileExt)
        source = set_field("source", None, Source.from_dict)  # type: ignore

        body = item_dict.get("body")
        history = [OperationSummary(**op) for op in item_dict.get("history", [])]
        relations = (
            ItemRelations(**item_dict["relations"]) if "relations" in item_dict else ItemRelations()
        )
        store_path = item_dict.get("store_path")

        # Other fields are basic strings or dicts.
        excluded_fields = [
            "type",
            "state",
            "format",
            "file_ext",
            "body",
            "source",
            "history",
            "relations",
            "store_path",
        ]
        all_fields = [f.name for f in cls.__dataclass_fields__.values()]
        allowed_fields = [f for f in all_fields if f not in excluded_fields]
        other_metadata = {key: value for key, value in item_dict.items() if key in allowed_fields}
        unexpected_metadata = {
            key: value for key, value in item_dict.items() if key not in all_fields
        }
        if unexpected_metadata:
            log.info("Skipping unexpected metadata on item: %s%s", info_prefix, unexpected_metadata)

        result = cls(
            type=type_,
            state=state,
            format=format,
            file_ext=file_ext,
            body=body,
            relations=relations,
            source=source,
            history=history,
            **other_metadata,
            store_path=store_path,
        )
        return result

    @classmethod
    def from_external_path(cls, path: Path, item_type: ItemType = ItemType.resource) -> "Item":
        """
        Create a resource Item for a file with a format inferred from the file extension
        or the content. Only sets basic metadata. Does not read the content.
        Raises `InvalidFilename` or `FileFormatError` if the file extension or format
        is unrecognized.
        """
        from kmd.file_storage.store_filenames import parse_item_filename
        from kmd.model.file_formats_model import detect_file_format

        # Will raise error for unrecognized file ext.
        name, filename_item_type, format, file_ext = parse_item_filename(path)
        if filename_item_type:
            item_type = filename_item_type
        if not format:
            format = detect_file_format(path)
        if not format:
            raise FileFormatError(f"Unrecognized file format: {fmt_loc(path)}")

        item = cls(
            type=item_type,
            title=name,
            file_ext=file_ext,
            format=format,
            external_path=str(path),
        )

        # Update modified time from the file system.
        item.set_modified(path.stat().st_mtime)

        return item

    @classmethod
    def from_media_metadata(cls, media_metadata: MediaMetadata) -> "Item":
        """
        Create an Item instance from MediaMetadata.
        """
        created_at = (
            datetime.combine(media_metadata.upload_date, datetime.min.time())
            if media_metadata.upload_date
            else datetime.now()
        )
        return cls(
            type=ItemType.resource,
            format=Format.url,
            title=media_metadata.title,
            url=media_metadata.url,
            description=media_metadata.description,
            thumbnail_url=media_metadata.thumbnail_url,
            created_at=created_at,
            extra={
                "media_id": media_metadata.media_id,
                "media_service": media_metadata.media_service,
                "upload_date": media_metadata.upload_date,
                "channel_url": media_metadata.channel_url,
                "view_count": media_metadata.view_count,
                "duration": media_metadata.duration,
                "heatmap": media_metadata.heatmap,
            },
        )

    def validate(self):
        """
        Sanity check the item to ensure it's consistent and complete enough to be saved.
        """
        if not self.format:
            raise ValueError(f"Item has no format: {self}")
        if self.type.expects_body and self.format.has_body and not self.body:
            raise ValueError(f"Item type `{self.type.value}` is text but has no body: {self}")

    @property
    def is_binary(self) -> bool:
        return bool(self.format and self.format.is_binary)

    def set_created(self, timestamp: float):
        self.created_at = datetime.fromtimestamp(timestamp, tz=timezone.utc)

    def set_modified(self, timestamp: float):
        self.modified_at = datetime.fromtimestamp(timestamp, tz=timezone.utc)

    def external_id(self) -> str:
        """
        Semi-permanent external id for the document (for indexing etc.).
        Currently just the store path.
        """
        if not self.store_path:
            raise ValueError("Cannot get doc id for an item that has not been saved")
        return str(self.store_path)

    def metadata(self, datetime_as_str: bool = False) -> Dict[str, Any]:
        """
        Metadata is all relevant non-None fields in easy-to-serialize form.
        Optional fields are omitted unless they are set.
        """

        item_dict = self.__dict__.copy()

        # Special case for prettier serialization of input path/hash.
        if self.source:
            item_dict["source"] = self.source.as_dict()

        def serialize(v: Any) -> Any:
            if isinstance(v, list):
                return [serialize(item) for item in v]
            elif isinstance(v, dict):
                return {k: serialize(v) for k, v in v.items()}
            elif isinstance(v, Enum):
                return v.value
            elif hasattr(v, "as_dict"):  # Handle Operation or any object with as_dict method.
                return v.as_dict()
            elif is_dataclass(v) and not isinstance(v, type):
                # Handle Python and Pydantic dataclasses.
                return asdict(v)
            else:
                return v

        # Convert enums and dataclasses to serializable forms.
        log.debug("Item metadata before serialization: %s", item_dict)
        item_dict = {
            k: serialize(v)
            for k, v in item_dict.items()
            if v is not None and k not in self.NON_METADATA_FIELDS
        }
        log.debug("Item metadata after serialization: %s", abbreviate_obj(item_dict))

        # Sometimes it's also better to serialize datetimes as strings.
        if datetime_as_str:
            for f, v in item_dict.items():
                if isinstance(v, datetime):
                    item_dict[f] = format_iso_timestamp(v)

        return item_dict

    def abbrev_title(self, max_len: int = 100, add_ops_suffix: bool = True) -> str:
        """
        Get or infer title. Optionally, include the last operation as a parenthetical
        at the end of the title.
        """
        title_raw_text = (
            self.title
            or self.url
            or self.description
            or (not self.is_binary and self.abbrev_body(max_len))
            or UNTITLED
        )

        suffix = ""
        if add_ops_suffix and self.type not in [ItemType.concept, ItemType.resource]:
            # For notes, exports, etc but not for concepts, add a parenthical note
            # indicating the last operation, if there was one. This makes filename slugs
            # more readable.
            last_op = self.history and self.history[-1].action_name
            if last_op:
                step_num = len(self.history) + 1 if self.history else 1
                suffix = f" (step{step_num:02d}, {last_op})"

        shorter_len = min(max_len, max(max_len - len(suffix), 20))
        clean_text = clean_up_title(
            abbreviate_phrase_in_middle(html_to_plaintext(title_raw_text), shorter_len)
        )

        final_text = clean_text
        if len(suffix) + len(clean_text) <= max_len:
            final_text += suffix

        return final_text

    @log_calls(level="warning")
    def abbrev_body(self, max_len: int) -> str:
        """
        Get a cut off version of the body text. Must not be a binary Item.
        Abbreviates YAML bodies like {"role": "user", "content": "Hello"} to "user Hello".
        """
        body_text = self.body_text()[:max_len]

        # Just for aesthetics especially for titles of chat files.
        if self.type in [ItemType.chat, ItemType.config] or self.format == Format.yaml:
            try:
                yaml_obj = list(new_yaml().load_all(self.body_text()))
                if len(yaml_obj) > 0:
                    body_text = " ".join(str(v) for v in yaml_obj[0].values())
            except Exception as e:
                log.warning("Error parsing YAML body: %s", e)

        return body_text[:max_len]

    def title_slug(self, max_len: int = SLUG_MAX_LEN) -> str:
        """
        Get a readable slugified version of the title for this item (may not be unique).
        """
        title = self.abbrev_title(max_len=max_len)
        slug = slugify(title, max_length=max_len, separator="_")
        return slug

    def abbrev_description(self, max_len: int = 1000) -> str:
        """
        Get or infer description.
        """
        return abbreviate_on_words(html_to_plaintext(self.description or self.body or ""), max_len)

    def read_as_config(self) -> Any:
        """
        If it is a config Item, return the parsed YAML.
        """
        if not self.type == ItemType.config:
            raise FileFormatError(f"Item is not a config: {self}")
        if not self.body:
            raise FileFormatError(f"Config item has no body: {self}")
        if self.format != Format.yaml:
            raise FileFormatError(f"Config item is not YAML: {self.format}: {self}")
        return from_yaml_string(self.body)

    def get_file_ext(self) -> FileExt:
        """
        Get or infer file extension.
        """
        if self.file_ext:
            return self.file_ext
        if self.is_binary and not self.file_ext:
            raise ValueError(f"Binary Items must have a file extension: {self}")
        inferred_ext = self.format and FileExt.for_format(self.format)
        if not inferred_ext:
            raise ValueError(f"Cannot infer file extension for Item: {self}")
        return inferred_ext

    def get_full_suffix(self) -> str:
        """
        Get the full file extension suffix (e.g. "note.md") for this item.
        """

        if self.type == ItemType.extension:
            # Python files cannot have more than one . in them.
            return f"{FileExt.py.value}"
        elif self.type == ItemType.script:
            # Same for kmd scripts.
            return f"{self.type.value}.{FileExt.ksh.value}"
        else:
            return f"{self.type.value}.{self.get_file_ext().value}"

    def full_text(self) -> str:
        """
        Get the full text of the item, including any title, description, and body.
        Use for embeddings.
        """
        parts = [self.title, self.description, self.body_text().strip()]
        return "\n\n".join(part for part in parts if part)

    def body_text(self) -> str:
        if self.is_binary:
            raise ValueError("Cannot get text content of a binary Item")
        return self.body or ""

    def body_as_html(self) -> str:
        if self.format == Format.html:
            return self.body_text()
        elif self.format == Format.plaintext:
            return plaintext_to_html(self.body_text())
        elif self.format == Format.markdown or self.format == Format.md_html:
            return markdown_to_html(self.body_text())

        raise ValueError(f"Cannot convert item of type {self.format} to HTML: {self}")

    def is_url_resource(self) -> bool:
        return self.type == ItemType.resource and self.format == Format.url and self.url is not None

    def _copy_and_update(
        self, other: Optional["Item"] = None, update_timestamp: bool = False, **kwargs
    ) -> Dict[str, Any]:
        overrides: Dict[str, Any] = {"store_path": None, "modified_at": None}
        if update_timestamp:
            overrides["created_at"] = datetime.now()

        fields = deepcopy(self.__dict__)

        if other:
            other_fields = deepcopy(other.__dict__)
            fields.update(other_fields)
            fields["extra"] = {**(self.extra or {}), **(other.extra or {})}

        fields.update(overrides)
        fields.update(kwargs)

        return fields

    def new_copy_with(self, update_timestamp: bool = True, **kwargs) -> "Item":
        """
        Copy item with the given field updates. Resets store_path to None. Updates
        created time if requested.
        """
        new_fields = self._copy_and_update(update_timestamp=update_timestamp, **kwargs)
        return Item(**new_fields)

    def merged_copy(self, other: "Item") -> "Item":
        """
        Copy item, merging in fields from another, with the other item's fields
        taking precedence. Resets store_path to None.
        """
        merged_fields = self._copy_and_update(other, update_timestamp=False)
        return Item(**merged_fields)

    def derived_copy(self, type: ItemType, **kwargs) -> "Item":
        """
        Same as `new_copy_with()`, but also updates `derived_from` relation.
        """
        if not self.store_path:
            raise ValueError(f"Cannot derive from an item that has not been saved: {self}")

        updates = kwargs.copy()
        updates["type"] = type

        # External resource paths only make sense for resources, so clear them out if new item
        # is not a resource.
        new_type = updates.get("type") or self.type
        if "external_path" not in updates and new_type != ItemType.resource:
            updates["external_path"] = None

        new_item = self.new_copy_with(update_timestamp=True, **updates)
        new_item.update_relations(derived_from=[self.store_path])

        return new_item

    def update_relations(self, **relations: List[str]) -> ItemRelations:
        """
        Update relations with the given field updates.
        """
        self.relations = self.relations or ItemRelations()
        for key, value in relations.items():
            setattr(self.relations, key, value)
        return self.relations

    def update_history(self, source: Source) -> None:
        """
        Update the history of the item with the given operation.
        """
        self.source = source
        self.add_to_history(source.operation.summary())

    def item_id(self) -> Optional[ItemId]:
        """
        Return identity of the item, or None if it should be treated as unique.
        """
        return ItemId.for_item(self)

    def content_equals(self, other: "Item") -> bool:
        """
        Check if two items have identical content, ignoring timestamps and store path.
        """
        # Check relevant metadata fields.
        self_fields = self.__dict__.copy()
        other_fields = other.__dict__.copy()
        for fields_dict in [self_fields, other_fields]:
            for f in ["created_at", "modified_at", "store_path", "body"]:
                fields_dict.pop(f, None)

        metadata_matches = self_fields == other_fields

        # Trailing newlines don't matter.
        body_matches = (
            self.is_binary == other.is_binary and self.body == other.body
        ) or self.body_text().rstrip() == other.body_text().rstrip()
        return metadata_matches and body_matches

    def add_to_history(self, operation_summary: OperationSummary):
        if not self.history:
            self.history = []
        # Don't add duplicates to the history.
        if not self.history or self.history[-1] != operation_summary:
            self.history.append(operation_summary)

    def fmt_path_or_title(self) -> str:
        """
        Formatted path or title, for error messages etc.
        """
        if self.store_path:
            return fmt_store_path(self.store_path)
        elif self.external_path:
            return fmt_loc(self.external_path)
        else:
            return repr(self.abbrev_title())

    def as_str_brief(self) -> str:
        return (
            abbreviate_obj(
                self,
                key_filter={
                    "store_path": 0,
                    "type": 64,
                    "title": 64,
                    "url": 64,
                    "external_path": 64,
                },
            )
            + f"[{len(self.body) if self.body else 0} body chars]"
        )

    def as_str(self) -> str:
        return (
            abbreviate_obj(
                self,
                key_filter={
                    "store_path": 0,
                    "external_path": 64,
                    "type": 64,
                    "state": 64,
                    "title": 64,
                    "url": 64,
                    "format": 64,
                    "created_at": 64,
                    "body": 64,
                },
            )
            + f"[{len(self.body) if self.body else 0} body chars]"
        )

    def __str__(self):
        return self.as_str_brief()


# Some reflection magic so the order of the YAML metadata for an item will match
# the order of the fields here.
ITEM_FIELDS = [f.name for f in Item.__dataclass_fields__.values()]


## Tests


def test_item_metadata_serialization():
    # Important to confirm StorePath is serialized like a Path.
    ir = ItemRelations(derived_from=[StorePath("docs/filename.doc.md")])
    assert asdict(ir) == {"derived_from": [StorePath("docs/filename.doc.md")], "diff_of": None}
